# -*- coding: utf-8 -*-
"""Veri temizleme lem .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PELb3hhDW1wz9emJVQaLqNlqPQGWNBRA
"""

import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer

# NLTK veri setlerini kontrol etme
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# 1. Veri Okuma (txt dosyasından yorumları okuma)
file_path = "filtered_reviews.txt"  # Dosya yolu
with open(file_path, 'r', encoding='utf-8') as file:
    reviews = file.readlines()

# 2. Veri Çerçevesine Dönüştürme
df = pd.DataFrame(reviews, columns=["Review"])

# 3. Temizlik Fonksiyonları

# - Özel karakterleri temizleme ve küçük harfe çevirme
def clean_text(text):
    # Tüm metni küçük harfe çevir
    text = text.lower()
    # "1. yorum:" ifadesini kaldır
    text = re.sub(r'^\d+\.\s*yorum:?\s*', '', text, flags=re.IGNORECASE)
    # Emojiler ve özel karakterleri kaldır
    text = re.sub(r'[^\w\s]', '', text)  # Noktalama işaretlerini kaldır
    text = re.sub(r'[^\x00-\x7F]+', '', text)  # Unicode karakterleri kaldır
    return text

# - Tokenization ve Stop-words (Durma kelimeleri) Temizleme
def remove_stopwords(text):
    stop_words = set(stopwords.words('english'))  # İngilizce stop-words
    word_tokens = word_tokenize(text)  # Kelimelere ayırma
    filtered_text = [word for word in word_tokens if word not in stop_words]
    return ' '.join(filtered_text)

# - Lemmatization (Kelime köklerine indirgeme)
def lemmatize_text(text):
    lemmatizer = WordNetLemmatizer()
    word_tokens = word_tokenize(text)
    lemmatized_text = [lemmatizer.lemmatize(word) for word in word_tokens]
    return ' '.join(lemmatized_text)

# 4. Adımları Uygulama
# Yorum ID ekleme
df['Comment_ID'] = df.index + 1  # Yorum ID'si olarak satır numarasını kullan
df['Cleaned_Review'] = df['Review'].apply(clean_text)  # Özel karakterleri temizle ve küçük harfe çevir
df['No_Stopwords'] = df['Cleaned_Review'].apply(remove_stopwords)  # Stop-words temizle
df['Lemmatized_Review'] = df['No_Stopwords'].apply(lemmatize_text)  # Lemmatize et

# 5. Sonuçları Görüntüleme
print(df[['Comment_ID', 'Review', 'Lemmatized_Review']].head())  # İlk birkaç satırı göster

# Sonuçları bir dosyaya kaydetmek isterseniz:
output_path = "cleaned_reviews_with_id.csv"
df.to_csv(output_path, index=False)

import pandas as pd

# Load the cleaned reviews CSV to check the column names
file_path = 'cleaned_reviews_with_id.csv'  # Update this path to the correct one

# Read the CSV file
cleaned_reviews_df = pd.read_csv(file_path)

# Print the column names of the dataset
print(cleaned_reviews_df.columns.tolist())

import pandas as pd

# Function to reload the file, clean it, and save the modified version
def clean_and_save_file(uploaded_file_path):
    # Load the file
    cleaned_reviews_df = pd.read_csv(uploaded_file_path)

    # Keep only 'Comment_ID' and 'Lemmatized_Review' columns
    df_cleaned = cleaned_reviews_df[['Comment_ID', 'Lemmatized_Review']]

    # Save the cleaned DataFrame to a new CSV file
    output_path = 'cleaned_reviews_with_lemmatized.csv'
    df_cleaned.to_csv(output_path, index=False)

    return output_path

# Use this function after uploading the file:
# clean_and_save_file('/path/to/your/uploaded/file.csv')

