# -*- coding: utf-8 -*-
"""autolabel ile model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f7SFU2BN3MhXK6ArE_ytE372J9Ik0v0r
"""



import pandas as pd
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# NLTK ve VADER'ı indirme (ilk kullanımda)
nltk.download('vader_lexicon')

# 1. Veri Okuma (Yorumlar içeren CSV dosyasını okuyoruz)
file_path = 'veriseti.csv'  # Dosya yolunu doğru şekilde ayarlayın
df = pd.read_csv(file_path)

# 2. VADER Duygu Analizörü başlatma
sia = SentimentIntensityAnalyzer()

# 3. Duygu Analizi ve Etiketleme
def label_sentiment(review):
    score = sia.polarity_scores(review)
    compound_score = score['compound']

    if compound_score >= 0.05:
        return 'Pozitif'
    elif compound_score <= -0.05:
        return 'Negatif'
    else:
        return 'Nötr'

# 4. Etiketleri Uygulama
df['Label'] = df['Lemmatized_Review'].apply(label_sentiment)

# 5. Sonuçları Görüntüleme
df_reduced = df[['Comment_ID','Lemmatized_Review', 'Label']]

# İlk 10 satırı yazdırma
print(df_reduced.head(10))  # İlk 10 satırı görüntüle

# 6. Etiketli veriyi yeni bir dosyaya kaydetme
output_path = 'auto_labeled_reviews.csv'  # Çıktıyı kaydedeceğiniz yolu belirleyin
df_reduced.to_csv(output_path, index=False)

print(f"Etiketlenmiş veriler kaydedildi: {output_path}")

#Gözetimli Sentiment Analizi

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder

# Veriyi Yükleyelim
file_path = "auto_labeled_reviews.csv"  # Yüklenen dosya yolu
df = pd.read_csv(file_path)

# 1. Veriyi hazırlama
X = df['Lemmatized_Review']  # Özellikler: Temizlenmiş ve lemmatize edilmiş yorumlar
y = df['Label']  # Etiketler: Pozitif, Negatif, Nötr

# 2. Etiketleri sayısal değerlere dönüştürme (Lojistik Regresyon ve SVM için gerekli)
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# 3. Eğitim ve Test Verisi Olarak Ayırma
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

# 4. TF-IDF Vektörizasyonu
vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)  # Maksimum 10000 kelime
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# 5. Modelleri Seçme ve Eğitme
# Lojistik Regresyon
log_reg_model = LogisticRegression(max_iter=1000)
log_reg_model.fit(X_train_tfidf, y_train)

# Destek Vektör Makinesi (SVM)
svm_model = SVC(kernel='linear')  # Lineer kernel kullanıyoruz
svm_model.fit(X_train_tfidf, y_train)

# 6. Eğitim ve Test Veri Setlerinde Sonuçları Hesaplayalım
# Lojistik Regresyon Modeli
log_reg_train_pred = log_reg_model.predict(X_train_tfidf)
log_reg_test_pred = log_reg_model.predict(X_test_tfidf)

# SVM Modeli
svm_train_pred = svm_model.predict(X_train_tfidf)
svm_test_pred = svm_model.predict(X_test_tfidf)

# Lojistik Regresyon - Eğitim Verisi Sonuçları
log_reg_train_accuracy = accuracy_score(y_train, log_reg_train_pred)
log_reg_train_precision = precision_score(y_train, log_reg_train_pred, average='weighted')
log_reg_train_recall = recall_score(y_train, log_reg_train_pred, average='weighted')
log_reg_train_f1 = f1_score(y_train, log_reg_train_pred, average='weighted')

# Lojistik Regresyon - Test Verisi Sonuçları
log_reg_test_accuracy = accuracy_score(y_test, log_reg_test_pred)
log_reg_test_precision = precision_score(y_test, log_reg_test_pred, average='weighted')
log_reg_test_recall = recall_score(y_test, log_reg_test_pred, average='weighted')
log_reg_test_f1 = f1_score(y_test, log_reg_test_pred, average='weighted')

# SVM - Eğitim Verisi Sonuçları
svm_train_accuracy = accuracy_score(y_train, svm_train_pred)
svm_train_precision = precision_score(y_train, svm_train_pred, average='weighted')
svm_train_recall = recall_score(y_train, svm_train_pred, average='weighted')
svm_train_f1 = f1_score(y_train, svm_train_pred, average='weighted')

# SVM - Test Verisi Sonuçları
svm_test_accuracy = accuracy_score(y_test, svm_test_pred)
svm_test_precision = precision_score(y_test, svm_test_pred, average='weighted')
svm_test_recall = recall_score(y_test, svm_test_pred, average='weighted')
svm_test_f1 = f1_score(y_test, svm_test_pred, average='weighted')

# Sonuçları Yazdıralım
print("Lojistik Regresyon - Eğitim Verisi Sonuçları:")
print(f"Doğruluk (Accuracy): {log_reg_train_accuracy:.4f}")
print(f"Kesinlik (Precision): {log_reg_train_precision:.4f}")
print(f"Hatırlama (Recall): {log_reg_train_recall:.4f}")
print(f"F1-Skoru (F1 Score): {log_reg_train_f1:.4f}")
print("\n")

print("Lojistik Regresyon - Test Verisi Sonuçları:")
print(f"Doğruluk (Accuracy): {log_reg_test_accuracy:.4f}")
print(f"Kesinlik (Precision): {log_reg_test_precision:.4f}")
print(f"Hatırlama (Recall): {log_reg_test_recall:.4f}")
print(f"F1-Skoru (F1 Score): {log_reg_test_f1:.4f}")
print("\n")

print("Destek Vektör Makinesi (SVM) - Eğitim Verisi Sonuçları:")
print(f"Doğruluk (Accuracy): {svm_train_accuracy:.4f}")
print(f"Kesinlik (Precision): {svm_train_precision:.4f}")
print(f"Hatırlama (Recall): {svm_train_recall:.4f}")
print(f"F1-Skoru (F1 Score): {svm_train_f1:.4f}")
print("\n")

print("Destek Vektör Makinesi (SVM) - Test Verisi Sonuçları:")
print(f"Doğruluk (Accuracy): {svm_test_accuracy:.4f}")
print(f"Kesinlik (Precision): {svm_test_precision:.4f}")
print(f"Hatırlama (Recall): {svm_test_recall:.4f}")
print(f"F1-Skoru (F1 Score): {svm_test_f1:.4f}")

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE

# Veriyi Yükleyelim
file_path = "auto_labeled_reviews.csv"  # Yüklenen dosya yolu
df = pd.read_csv(file_path)

# 1. Veriyi hazırlama
X = df['Lemmatized_Review']  # Özellikler: Temizlenmiş ve lemmatize edilmiş yorumlar
y = df['Label']  # Etiketler: Pozitif, Negatif, Nötr

# 2. Etiketleri sayısal değerlere dönüştürme (Lojistik Regresyon ve SVM için gerekli)
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# 3. Eğitim ve Test Verisi Olarak Ayırma
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

# 4. TF-IDF Vektörizasyonu ve Ngram Kullanımı
vectorizer = TfidfVectorizer(stop_words='english', max_features=10000, ngram_range=(1, 2))  # 1 ve 2 gramları kullanıyoruz
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# 5. SMOTE ile Dengesiz Sınıfları Dengeleyelim
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train_tfidf, y_train)

# 6. Modelleri Seçme ve Hiperparametre Ayarları (GridSearchCV ile)
# Lojistik Regresyon için hiperparametre ayarları
log_reg_params = {
    'C': [0.1, 1, 10],
    'penalty': ['l2', 'none'],
    'solver': ['liblinear', 'lbfgs']
}

# SVM için hiperparametre ayarları
svm_params = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf'],
    'gamma': ['scale', 'auto']
}

# GridSearchCV için Grid aramaları
log_reg_grid_search = GridSearchCV(LogisticRegression(max_iter=1000), log_reg_params, cv=5, n_jobs=-1, verbose=1)
svm_grid_search = GridSearchCV(SVC(), svm_params, cv=5, n_jobs=-1, verbose=1)

# 7. Modelleri Eğitelim
log_reg_grid_search.fit(X_train_smote, y_train_smote)
svm_grid_search.fit(X_train_smote, y_train_smote)

# 8. En İyi Parametreleri Yazdıralım
print(f"Lojistik Regresyon için en iyi parametreler: {log_reg_grid_search.best_params_}")
print(f"SVM için en iyi parametreler: {svm_grid_search.best_params_}")

# 9. Test Verisi ile Sonuçları Değerlendirelim
log_reg_best_model = log_reg_grid_search.best_estimator_
svm_best_model = svm_grid_search.best_estimator_

# Lojistik Regresyon Modeli
log_reg_test_pred = log_reg_best_model.predict(X_test_tfidf)

# SVM Modeli
svm_test_pred = svm_best_model.predict(X_test_tfidf)

# 10. Model Performans Metriklerini Hesaplayalım
log_reg_accuracy = accuracy_score(y_test, log_reg_test_pred)
log_reg_precision = precision_score(y_test, log_reg_test_pred, average='weighted')
log_reg_recall = recall_score(y_test, log_reg_test_pred, average='weighted')
log_reg_f1 = f1_score(y_test, log_reg_test_pred, average='weighted')

svm_accuracy = accuracy_score(y_test, svm_test_pred)
svm_precision = precision_score(y_test, svm_test_pred, average='weighted')
svm_recall = recall_score(y_test, svm_test_pred, average='weighted')
svm_f1 = f1_score(y_test, svm_test_pred, average='weighted')

# 11. Sonuçları Yazdıralım
print("\nLojistik Regresyon Sonuçları:")
print(f"Doğruluk (Accuracy): {log_reg_accuracy:.4f}")
print(f"Kesinlik (Precision): {log_reg_precision:.4f}")
print(f"Hatırlama (Recall): {log_reg_recall:.4f}")
print(f"F1-Skoru (F1 Score): {log_reg_f1:.4f}")
print("\n")

print("Destek Vektör Makinesi (SVM) Sonuçları:")
print(f"Doğruluk (Accuracy): {svm_accuracy:.4f}")
print(f"Kesinlik (Precision): {svm_precision:.4f}")
print(f"Hatırlama (Recall): {svm_recall:.4f}")
print(f"F1-Skoru (F1 Score): {svm_f1:.4f}")

pip install transformers

#Zero-Shot Sentiment Analizi

import pandas as pd
from transformers import pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split

# 1. Veriyi Yükleme
file_path = "auto_labeled_reviews.csv"  # Yüklenen dosya yolu
df = pd.read_csv(file_path)

# 2. Veriyi Eğitim ve Test Verilerine Ayıralım
X = df['Lemmatized_Review']
y = df['Label']
y_encoded = y.map({'Pozitif': 0, 'Negatif': 1, 'Nötr': 2})

X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

# 3. Zero-shot sınıflandırma pipeline'ını oluşturuyoruz
classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")

# 4. Test verisi üzerinde tahminleri alıyoruz
labels = ['Pozitif', 'Negatif', 'Nötr']
predictions = []

for text in X_test:
    result = classifier(text, candidate_labels=labels)
    predictions.append(result['labels'][0])  # En yüksek puanı alan etiket

# 5. Değerlendirme
accuracy = accuracy_score(y_test, [labels.index(pred) for pred in predictions])
precision = precision_score(y_test, [labels.index(pred) for pred in predictions], average='weighted')
recall = recall_score(y_test, [labels.index(pred) for pred in predictions], average='weighted')
f1 = f1_score(y_test, [labels.index(pred) for pred in predictions], average='weighted')

# 6. Sonuçları Yazdıralım
print(f"Doğruluk (Accuracy): {accuracy:.4f}")
print(f"Kesinlik (Precision): {precision:.4f}")
print(f"Hatırlama (Recall): {recall:.4f}")
print(f"F1-Skoru (F1 Score): {f1:.4f}")

#Sonuçları Karşılaştırma ve Analiz

import numpy as np
import matplotlib.pyplot as plt
# Lojistik Regresyon ve SVM modelinin metrik sonuçları
log_reg_accuracy = 0.7258
log_reg_precision = 0.7545
log_reg_recall = 0.7258
log_reg_f1 = 0.6708

svm_accuracy = 0.7456
svm_precision = 0.7393
svm_recall = 0.7456
svm_f1 = 0.7156

# Zero-Shot Modelinin metrik sonuçları
zero_shot_accuracy = 0.2327  # Buraya zero-shot modelinin accuracy sonucunu yazın
zero_shot_precision = 0.2988  # Buraya zero-shot modelinin precision sonucunu yazın
zero_shot_recall = 0.2327  # Buraya zero-shot modelinin recall sonucunu yazın
zero_shot_f1 = 0.1291  # Buraya zero-shot modelinin F1 sonucu yazın

# Metrikler
models = ['Lojistik Regresyon', 'SVM', 'Zero-Shot']
accuracy = [log_reg_accuracy, svm_accuracy, zero_shot_accuracy]
precision = [log_reg_precision, svm_precision, zero_shot_precision]
recall = [log_reg_recall, svm_recall, zero_shot_recall]
f1_score = [log_reg_f1, svm_f1, zero_shot_f1]

# Grafik boyutlarını ayarlayalım
x = np.arange(len(models))  # Model isimlerinin indeksleri
width = 0.2  # Her çubuğun genişliği

# Grafik oluşturma
fig, ax = plt.subplots(figsize=(10, 6))

# Çubukları çizme
rects1 = ax.bar(x - width*1.5, accuracy, width, label='Doğruluk (Accuracy)', color='b')
rects2 = ax.bar(x - width/2, precision, width, label='Kesinlik (Precision)', color='g')
rects3 = ax.bar(x + width/2, recall, width, label='Hatırlama (Recall)', color='r')
rects4 = ax.bar(x + width*1.5, f1_score, width, label='F1-Skoru (F1 Score)', color='y')

# Eksen etiketleri ve başlık
ax.set_xlabel('Modeller')
ax.set_ylabel('Skorlar')
ax.set_title('Gözetimli ve Zero-Shot Modellerin Performans Karşılaştırması')
ax.set_xticks(x)
ax.set_xticklabels(models)
ax.legend()

# Barların üzerlerine skorları yazalım
def add_labels(rects):
    for rect in rects:
        height = rect.get_height()
        ax.annotate(f'{height:.4f}',
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),  # Y-ekseni ofseti
                    textcoords="offset points",
                    ha='center', va='bottom')

# Etiketleri ekle
add_labels(rects1)
add_labels(rects2)
add_labels(rects3)
add_labels(rects4)

# Göster
plt.tight_layout()
plt.show()